---
title: "Entregable1"
author: "Norberto García Marín y María Soledad Pérez López"
date: "November 29, 2018"
output: pdf_document
---

# 1. Índice


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
##para que no se ejecuten el cacho de código
library(ggplot2)
library(lattice)
library(caret)
library(e1071)
library(ellipse)
library(doParallel)
library(rpart)
library(gbm)

```

Primero cargaremos las librerías necearias para la ejecución de las funciones que necesitaremos.

# 2. Carga de la base de datos

```{r}
#Cargad de la base de datos

credit <-read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data", sep = ",", na.strings = "?", header = F)
colnames(credit) <- c("Male", "Age", "Debt", "Married", "BankCustomer", "EducationLevel", "Ethnicity", "YearsEmployed", "PriorDefaul", "Employed", "CreditScore", "DriversLicense", "Citizen", "ZipCode", "Income","Approved")

# Informacion de los atributos. Columnas
# Male:	b, a. 
# Age:	continuous. 
# Debt:	continuous. 
# Married:	u, y, l, t. 
# BankCustomer:	g, p, gg. 
# EducationLevel:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff. 
# Ethnicity:	v, h, bb, j, n, z, dd, ff, o. 
# YearsEmployed:	continuous. 
# PriorDefaul:	t, f. 
# Employed:	t, f. 
# CreditScore: continuous. 
# DriversLicense:	t, f. 
# Citizen: g, p, s. 
# ZipCode: continuous. 
# Income: continuous. 
# Approved: +,- (Si ha sido aprobado, esta es la variable de salida)

```

# 3. Preprocesar Datos

## 3.1. Analizar las variables 

### 3.1.1. Análisis monovariable

```{r setup, include=FALSE}

###########Funciones auxiliares###########
qqplot.data <- function (vec)   
{        
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))   
  x <- qnorm(c(0.25, 0.75))                       
  slope <- diff(y)/diff(x)          
  int <- y[1L] - slope * x[1L]       
  d <- data.frame(resids = vec)     
  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope,intercept = int)   
}                                                                                               


# Resumen de los todos los datos

summary(credit)

```



Las variables que vamos a analizar serán: 

```{r}

#######Análisis variable Male #######
# Variable No Numérica                                                                                
# Resumen                          
summary(credit[1], maxsum = Inf)
# Numero de ocurrencias (porcentaje)    
porcent <- prop.table(table(credit$Male)) * 100
cbind(total=table(credit$Male), porcentaje=porcent) 
# Grafico de barras    
barplot(table(credit$Male))

```




```{r setup, include=FALSE}
#######Análisis variable Age#######
# Variable Continua  
# Resumen    
summary(credit[2], maxsum = Inf)                                                             
# Numero de ocurrencias (porcentaje)     
porcent <- prop.table(table(credit$Age)) * 100   
cbind(total=table(credit$Age), porcentaje=porcent)                                             
# Histograma con frecuencias de aparicion


# Estimacion de la fucnión de desidad de probabilidad          
dens<-density(credit$Age,na.rm=T)                             
hist(credit$Age,xlab="",main="Age",ylim=c(0,max(dens$y)*1.1),probability =T) 
lines(dens)                                                                 
# rug() apra la repersentacion de lso valores reales del atributo, bajo el eje x                      #
# jitter() para añadir un poco de ruido aleatorio a los valores verdaderos,                           #
# por si hubiese valores repetidos                                                                    #
rug(jitter(credit$Age))                                         
# Diagrama Box-Whisker. Informacion sobre la dispersion, asimetria estadistica y posibles valores atípicos
boxplot(credit$Age,main="Age")                                       
# Representacion de los percentiles con respecto a los de una normal centrada en cero 
qqplot.data(credit$Age)+ggtitle("Gráfica Q-Q para Age")

```




```{r}
#######Análisis variable Debt#######
# Variable Continua                                                                                   #
# Resumen                                                                                             #
summary(credit[3], maxsum = Inf)      
# Numero de ocurrencias (porcentaje)    
porcent <- prop.table(table(credit$Debt)) * 100     
cbind(total=table(credit$Debt), porcentaje=porcent)           
# Histograma con frecuencias de aparición             
# Estimacion de la fucnion de desidad de probabilidad   
dens<-density(credit$Debt,na.rm=T)                    
hist(credit$Debt,xlab="",main="Debt",ylim=c(0,max(dens$y)*1.1),probability =T)    
lines(dens)                     
rug(jitter(credit$Debt))                            

# Diagrama Box-Whisker. Informacion sobre la dispersion, asimetria estadistica y posibles valores atipicos  
boxplot(credit$Debt,main="Debt")        
# Representacion de los percentiles con respecto a los de una normal centrada en cero  
qqplot.data(credit$Debt)+ggtitle("Gráfica Q-Q para Debt")                                                
```



```{r}
#######Análisis variable Married######
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[4], maxsum = Inf)             
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$Married)) * 100                                                         #
cbind(total=table(credit$Married), porcentaje=porcent)     
# Grafico de barras                                                                                   #
barplot(table(credit$Married))           

```



```{r}
#######Análisis variable BankCustomer#######
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[5], maxsum = Inf)      
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$BankCustomer)) * 100                                                         #
cbind(total=table(credit$BankCustomer), porcentaje=porcent)   
# Grafico de barras                                                                                   #
barplot(table(credit$BankCustomer))       

```





```{r}
#######Análisis variable EducationLevel################
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[6], maxsum = Inf)              
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$EducationLevel)) * 100                                                         #
cbind(total=table(credit$EducationLevel), porcentaje=porcent)   
# Grafico de barras                                                                                   #
barplot(table(credit$EducationLevel))     

```




```{r}
#######Análisis variable Ethnicity#################
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[7], maxsum = Inf)             
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$Ethnicity)) * 100                                                         #
cbind(total=table(credit$Ethnicity), porcentaje=porcent)   
# Grafico de barras                                                                                   #
barplot(table(credit$Ethnicity))      

```




```{r}
#######Análisis variable YearsEmployed#################
# Variable Continua                                                                                   #
# Resumen                                                                                             #
summary(credit[8], maxsum = Inf)                
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$YearsEmployed)) * 100                                                         #
cbind(total=table(credit$YearsEmployed), porcentaje=porcent)  
# Histograma con frecuencias de aparicion                                                             #
# Estimacion de la fucnion de desidad de probabilidad                                                 #
dens<-density(credit$YearsEmployed,na.rm=T)                                                                      #
hist(credit$YearsEmployed,xlab="",main="YearsEmployed",ylim=c(0,max(dens$y)*1.1),probability =T)                            #
lines(dens)                                                                                           #
# rug() apra la repersentacion de lso valores reales del atributo, bajo el eje x                      #
# jitter() para añadir un poco de ruido aleatorio a los valores verdaderos,                           #
# por si hubiese valores repetidos                                                                    #
rug(jitter(credit$YearsEmployed))         
# Diagrama Box-Whisker. Informacion sobre la dispersion, asimetria estadistica                        #
# y posibles valores atipicos                                                                         #
boxplot(credit$YearsEmployed,main="YearsEmployed")    
# Representacion de los percentiles con respecto a los de una normal centrada en cero                 #
qqplot.data(credit$YearsEmployed)+ggtitle("Gráfica Q-Q para YearsEmployed")                                                 #
                                                  
```




```{r}
#######Análisis variable PriorDefaul#############
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[9], maxsum = Inf)         
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$PriorDefaul)) * 100                                                         #
cbind(total=table(credit$PriorDefaul), porcentaje=porcent)  
# Grafico de barras                                                                                   #
barplot(table(credit$PriorDefaul))       

```




```{r}
#######Análisis variable Employed######################
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[10], maxsum = Inf)           
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$Employed)) * 100                                                        #
cbind(total=table(credit$Employed), porcentaje=porcent)     
# Grafico de barras                                                                                   #
barplot(table(credit$Employed))      

```




```{r}
#######Análisis variable CreditScore####################
# Variable Continua                                                                                   #
# Resumen                                                                                             #
summary(credit[11], maxsum = Inf)         
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$CreditScore)) * 100                                                        #
cbind(total=table(credit$CreditScore), porcentaje=porcent)                                                              #
# Histograma con frecuencias de aparicion                                                             #
# Estimacion de la fucnion de desidad de probabilidad                                                 #
dens<-density(credit$CreditScore,na.rm=T)                                                                     #
hist(credit$CreditScore,xlab="",main="CreditScore",ylim=c(0,max(dens$y)*1.1),probability =T)                          #
lines(dens)                                                                                           #
# rug() apra la repersentacion de lso valores reales del atributo, bajo el eje x                      #
# jitter() para añadir un poco de ruido aleatorio a los valores verdaderos,                           #
# por si hubiese valores repetidos                                                                    #
rug(jitter(credit$CreditScore))           
# Diagrama Box-Whisker. Informacion sobre la dispersion, asimetria estadistica                        #
# y posibles valores atipicos                                                                         #
boxplot(credit$CreditScore,main="CreditScore")      
# Representacion de los percentiles con respecto a los de una normal centrada en cero                 #
qqplot.data(credit$CreditScore)+ggtitle("Gráfica Q-Q para CreditScore")                                               #

```



```{r}
#######Análisis variable DriversLicense###############
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[12], maxsum = Inf)                
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$DriversLicense)) * 100                                                        #
cbind(total=table(credit$DriversLicense), porcentaje=porcent)       
# Grafico de barras                                                                                   #
barplot(table(credit$DriversLicense))           
```



```{r}
#######Análisis variable Citizen####################
# Variable No Numérica                                                                                   #
# Resumen                                                                                             #
summary(credit[13], maxsum = Inf)                  
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$Citizen)) * 100                                                        #
cbind(total=table(credit$Citizen), porcentaje=porcent)  
# Grafico de barras                                                                                   #
barplot(table(credit$Citizen))               

```



```{r}
#######Análisis variable ZipCode#############
# Variable Continua                                                                                   #
# Resumen                                                                                             #
summary(credit[14], maxsum = Inf)            
# Numero de ocurrencias (porcentaje)                                                                  #
porcent <- prop.table(table(credit$ZipCode)) * 100                                                        #
cbind(total=table(credit$ZipCode), porcentaje=porcent)   
# Histograma con frecuencias de aparicion                                                             #
# Estimacion de la fucnion de desidad de probabilidad                                                 #
dens<-density(credit$ZipCode,na.rm=T)                                                                     #
hist(credit$ZipCode,xlab="",main="ZipCode",ylim=c(0,max(dens$y)*1.1),probability =T)                          #
lines(dens)                                                                                           #
# rug() apra la repersentacion de lso valores reales del atributo, bajo el eje x                      #
# jitter() para añadir un poco de ruido aleatorio a los valores verdaderos,                           #
# por si hubiese valores repetidos                                                                    #
rug(jitter(credit$ZipCode))            
# Diagrama Box-Whisker. Informacion sobre la dispersion, asimetria estadistica                        #
# y posibles valores atipicos                                                                         #
boxplot(credit$ZipCode,main="ZipCode")             
# Representacion de los percentiles con respecto a los de una normal centrada en cero                 #
qqplot.data(credit$ZipCode)+ggtitle("Gráfica Q-Q para ZipCode") 

```



```{r}

#######Análisis variable Income############
# Variable Continua                                                                                   #
# Resumen                                                                                             #
summary(credit[15], maxsum = Inf)             
# Numero de ocurrencias (porcentaje)       
porcent <- prop.table(table(credit$Income)) * 100     
cbind(total=table(credit$Income), porcentaje=porcent)        
# Histograma con frecuencias de aparicion                                                             #
# Estimacion de la fucnion de desidad de probabilidad       
dens<-density(credit$Income,na.rm=T)                         
hist(credit$Income,xlab="",main="Income",ylim=c(0,max(dens$y)*1.1),probability =T) 
lines(dens)                                                                                           #
# rug() apra la repersentacion de lso valores reales del atributo, bajo el eje x                      #
# jitter() para añadir un poco de ruido aleatorio a los valores verdaderos,                           #
# por si hubiese valores repetidos                                                                    #
rug(jitter(credit$Income))     
# Diagrama Box-Whisker. Informacion sobre la dispersion, asimetria estadistica                        #
# y posibles valores atipicos                                                                         #
boxplot(credit$Income,main="Income")              
# Representacion de los percentiles con respecto a los de una normal centrada en cero                 #
qqplot.data(credit$Income)+ggtitle("Gráfica Q-Q para Income") 

```


Se eliminará la variable ZipCode por no tener información relevante que sirva para el resto del análisis.

```{r}

credit.Datos<-credit
credit.Datos$ZipCode<-NULL

```


###3.1.2. Análisis  multivariable

Para hacer las multivariables haremos uniones con la variable de clase [de salida ( +,-)], para ver como influyen. 

Calcularemos el coeficiente de correlación, matriz de correlación para poder comprender mejor lo que ocurre con el análisis 

```{r}
#pairs(credit[,2],col=as.numeric(credit$Approved))
#pairs(credit,credit$Approved)
#featurePlot(x=iris[,1:4],y=iris[,5],plot="ellipse")
featurePlot(x=credit[,2],y=credit[,16],plot="density")
###Variable Male table(credit$Male)


y = credit[16]
#Variable Age
featurePlot(x=credit[,2],y=credit[,16],plot="density")
##pairs(credit[,1],col=as.factor(credit$Approved))

#Variable Debt
featurePlot(x=credit[,3],y=credit[,16],plot="density")

```




## 3.2. Tratar valores nulos, extremos o atípicos

### 3.2.1. Tratamiento de valores nulos

Para tomar medida de cuán serio es el problema de los valores nulos, debemos contar los casos que tienen valores nulos

```{r}
# Tratamiento de valores nulos

# Elementos que queremos tratar
tibble::rowid_to_column(credit.Datos)[!complete.cases(credit.Datos),]

# Numero de filas con nulos
print("Numero de filas con valores nulos")
nrow(credit.Datos[!complete.cases(credit.Datos),])

# Porcentaje de valores nulos
print("Porcentaje de filas con valores nulos")
nrow(credit.Datos[!complete.cases(credit.Datos),])/nrow(credit.Datos)*100

```

Como vemos tenemos 31 filas con valores filas con valores nulos, lo  que supone un 4,5% de casos.

No es recomendable deshacernos de los nulos sin más, ademas no hay ningun ejemplar que tenga muchas variables con valores nulos, por lo tanto la solucion seriá sustituirlas mediante valores representativos.


#### 3.2.1.1. Sustitución mediante valores representativos

Como la muestra tiene una distribucion desplazada skewed para todas las variables continuas, la mediana es la mejor opcion como valor central para sustituir.

Para las variables no continuas sustituiremos los valores nulos por el valor que mas se repita


```{r}
# Tratamiento de las variables en funcion de si es continua o no continua
credit.fix<-credit.Datos
continua<-c(FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE,FALSE,FALSE,TRUE)

for(i in 1:14){
  if(continua[i]){
    nulos <- subset(credit.fix, is.na(credit.fix[,i])) 
    credit.fix[as.numeric(rownames(nulos)), i] <-median(credit.fix[[i]],na.rm=T)
    
  } else {
    valorMasRepetido<-tail(names(sort(table(credit.Datos[i]))), 1) 
    nulos <- subset(credit.fix, is.na(credit.fix[,i])) 
    credit.fix[as.numeric(rownames(nulos)), i] <- valorMasRepetido
  }
}

```

Y comprobamos si se han sustituido correctamente

```{r}
print("Porcentaje de filas con valores nulos")
nrow(credit[!complete.cases(credit.fix),])/nrow(credit.fix)*100
```


### 3.2.2.  Tratamiento de valores extremos/atípicos

Sustitucion de los valores extremos y atipicos por la mediana de la variable en cuestion

```{r}
for(i in 1:14){
  if(!continua[i]) next;
  
  extremos<-boxplot(credit.fix[i],boxwex=0.15,plot=F)$out
  porArriba<-min(extremos[extremos > median(na.omit(credit.fix[[i]]))])
  porArribaSet <- credit.fix[credit.fix[i]>porArriba,]
  credit.fix[as.numeric(rownames(porArribaSet)), i] <- median(credit.fix[[i]],na.rm=T)
}
```



## 3.2.3. Dividir datos en Train/Test

Ahora que se han pre-procesado los datos parcialmente (Tratando los outliners y nulos) se debe separar el dataset en dos conjuntos

```{r}
credit.trainIdx<-readRDS("credit.trainIdx.rds")
credit.Datos.Train<-credit.fix[credit.trainIdx,]
credit.Datos.Test<-credit.fix[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Test)
```






## 3.3. Eliminar variables superfluas y añadir variables nuevas

### 3.3.1. Eliminar variables con poca varianza

Vamos a intentar eliminar variables con poca varianza.
Cuando una variable tiene poca varianza indica que carece de mucha informacion para crear distinciones entre los datos. Esto puede generar problemas a muchos algoritmos de machine learning

Vemos si existe alguna variable con esta caracteristica
```{r}
nearZeroVar(credit.Datos.Train)
```

Vemos que no existe ninguna variable, por lo tanto dejamos el dataset como esta.

### 3.3.2. Eliminar variables correladas

Cuando dos variables están muy correladas entre ellas basicamente representan la misma información. Suele ser interesante eliminar una de dichas variables y simplificar el modelo al tener menos variables de entrada.

Vemos si existen variables de este tipo:
```{r}
# Seleccionamos las variables de entrada
datos.input<-credit.Datos.Train[,1:14]
# Obtenemos la correlación solo de las variables numéricas de las variables de entrada
datos.cor<-cor(na.omit(datos.input[,sapply(datos.input,FUN=is.numeric)]))
# Obtenemos los nombres de las columnas num ́ericas de entrada correladas
colsToRemove<-labels(datos.cor)[[1]][findCorrelation(datos.cor,cutoff=0.85)]
# Eliminamos las columnas correladas del conjunto completo
credit.nocorr<-credit.Datos.Train[setdiff(names(credit.Datos.Train),colsToRemove)]
```

Comprobamos si el dataset de entrada y el de nocorr son diferentes

```{r}
identical(credit.nocorr,credit.Datos.Train)
```
No hay ninguna variable correlada por lo que no se puede eliminar nada.


### 3.3.3. Crear Dummy Variables
Las Variables Dummy es una forma de transformar factores en un conjunto de variables num ́ericas dondecada nivel es ortogonal al resto de variables dummy para ese factor.
as variables dummy son necesarias en algunos modelos matem ́aticos que trabajan con la matrizde atributos y valores de entrada.

Como caret transforma por defecto las variables de entrada que son factores creando dummy variables no haremos esta transformación de forma manual.





## 3.4. Transformar los datos

### 3.4.1. Escalado

El cambio de escala se aplica a las variables para normalizarlas y ponerlas todas en una escala común. Esto se hace tanto para mejorar la comprensión sobre su distribución y poder compararlas más facilmente evitándo la distorsión de diferencia de escalas como por el hecho de que de esta manera se evitan problemas con los algoritmos de ajuste de modelos que no posean la propiedad de invarianza al escalado como, por ejemplo, los algoritmos basados en gradiente descente (como las redes neuronales que usen backpropagation).


```{r}
# Semilla de números aleatorios
#set.seed(1234) -> no necesario, Eso lo usas cuando quieres que se pueda repetir el experimento tal cual lo has hecho, Escalar el conjunto de datos siempre lo va a hacer igual

# Dataset a utilizar. Sus variables de entrada y salida.
# Variable a predecir, variables de entrada a usar y variables que se escalarán.
credit.Var.Salida.Usada<-c("Approved")
credit.Vars.Entrada.Usadas<-c("Age", "Debt", "YearsEmployed","CreditScore", "Income")
# Por si algunas se ignoran
credit.Vars.Entrada.Escaladas<-credit.Vars.Entrada.Usadas # Vars a escalar

# Solo indicamos las variables que vayamos a transformar (y usamos TRAIN)
credit.preProc.CS.Mod<-preProcess(credit.Datos.Train[credit.Vars.Entrada.Escaladas],
  method=c("center","scale"))

# Obtenemos la transformación
credit.Datos.Train.Transf.CS<-predict(credit.preProc.CS.Mod,credit.Datos.Train)
credit.Datos.Test.Transf.CS<-predict(credit.preProc.CS.Mod,credit.Datos.Test)

```


Ahora podemos ver el efecto del escalado sobre las variables de entrada y comprobamos que estas estén en la misma escala y estén centradas.

```{r, warning=FALSE}
# Dibujar un diagrama de densidad para las variables que han sido escaladas
VarToPlot<-credit.Vars.Entrada.Escaladas
d1<-densityplot(
  formula(paste("~",paste(VarToPlot,sep="",collapse =" + "),collapse="")),
  data=credit.Datos.Train,main="Variables sin Normalizar",plot.points=F,xlim = c(0,8),xlab = "Valores Variables Entrada")
d2<-densityplot(
  formula(paste("~",paste(VarToPlot,sep="",collapse =" + "),collapse="")),
  data=credit.Datos.Train.Transf.CS, main="Variables Normalizadas",plot.points=F, xlab = "Valores Variables Entrada", xlim = c(-2,4))
# Gráficos en blanco y negro (mejor para imprimir)
trellis.par.set(theme = standard.theme("pdf",color=FALSE))
print(d1,position=c(0,0,0.5,1),more=T)
print(d2,position=c(0.5,0,1,1))
# Volvemos a gráficos normales
trellis.par.set(theme = standard.theme("pdf"))
```


### 3.4.2. Transformaciones de relaciones entre variables

No es necesario, ya que cuando hicimos el estudio para eliminar variables correladas comprobamos que no existían.

### 3.4.3. Transformaciones de distribuciones asimétricas

Observando las gráficas anteriores podemos darnos cuenta de la asimetría que existe en algunas variables. Para tratar que los datos sean lo más "gausianos"(o normales) posibles vamos a aplicar tranformaciones en la función preProcess(). Usaremos el método YeoJohnson porque necesitamos que se puedan tratar valores negativos.


```{r, warning=FALSE}

credit.preProc.CS.Mod.BC<-preProcess(credit.Datos.Train[credit.Vars.Entrada.Escaladas], method=c("center","scale", "BoxCox"))

# Obtenemos la transformación
credit.Datos.Train.Transf.CS.BC<-predict(credit.preProc.CS.Mod.BC,credit.Datos.Train)
credit.Datos.Test.Transf.CS.BC<-predict(credit.preProc.CS.Mod.BC,credit.Datos.Test)


d1<-densityplot(
  formula(paste("~",paste(VarToPlot,sep="",collapse =" + "),collapse="")),
  data=credit.Datos.Train,main="Variables sin Normalizar",plot.points=F)

d3<-densityplot(
  formula(paste("~",paste(VarToPlot,sep="",collapse =" + "),collapse="")),
  data=credit.Datos.Train.Transf.CS.BC, main="Variables Aplicado BC",plot.points=F)

trellis.par.set(theme = standard.theme("pdf",color=FALSE))
print(d1,position=c(0,0,0.5,1),more=T)
print(d3,position=c(0.5,0,1,1))
# Volvemos a gráficos normales
trellis.par.set(theme = standard.theme("pdf"))

```


Como no queremos perder información que puede ser relevante no vamos a aplicar las técnicas de Binning ni Bloqueo.



### 3.4.4. Crear nuevas variables

```{r, warning=FALSE}
# Ejemplo de crear nuevas variables con Class Distribution
credit.preProc.ClssDtrb.Mod<-classDist(credit.Datos.Train.Transf.CS.BC[credit.Vars.Entrada.Escaladas],credit.Datos.Train.Transf.CS.BC[,15])
# A~nadimos las nuevas variables
credit.xtra.Vars<-cbind(credit.Datos.Train.Transf.CS.BC,predict(credit.preProc.ClssDtrb.Mod, credit.Datos.Train.Transf.CS.BC[credit.Vars.Entrada.Escaladas]))
credit.xtra.VarsTest<-cbind(credit.Datos.Test.Transf.CS.BC,predict(credit.preProc.ClssDtrb.Mod, credit.Datos.Test.Transf.CS.BC[credit.Vars.Entrada.Escaladas]))

# Dibujamos las nuevas variables y las antiguas
p1<-featurePlot(x=predict(credit.preProc.ClssDtrb.Mod, credit.xtra.Vars[credit.Vars.Entrada.Escaladas]), credit.xtra.Vars[,15],plot="ellipse")

p2<-featurePlot(x=credit.xtra.Vars[credit.Vars.Entrada.Escaladas], credit.xtra.Vars[,15],plot="ellipse")

print(p1,position=c(0,0,0.5,1),more=T)
print(p2,position=c(0.5,0,1,1))
```

De ahora en adelante para simpleficar el nombre del dataset a utilizar guardaremos el train y test en credit.Train.Preprocesado y credit.Test.Preprocesado

```{r}
credit.Train.Preprocesado<-credit.xtra.Vars
credit.Test.Preprocesado<-credit.xtra.VarsTest
```


Ahora que tenemos el preprocesado de datos hecho, pasaremos al entrenamiento de los diferentes modelos y técnicas.

# 4. Entrenar varios Modelos/Técnicas


## 4.1. Escoger varios modelos/técnicas a comparar


### 4.1.1. Modelo GLM (Generalized Linear Model)



### 4.1.2. Modelo RPART

El algoritmo CART de árboles de decisión de clasificación y regresión.
Para la búsqueda de hiper-parámetros vamos a usar tuneLeght de la función train, como lo visto en clase vamos a decirdidr que el número de combinaciones a probar sea 10.

### 4.1.3. Modelo RF

El algoritmo CART de árboles de decisión de clasificación y regresión.
Para la búsqueda de hiper-parámetros vamos a usar tuneLeght de la función train, como lo visto en clase vamos a decirdidr que el número de combinaciones a probar sea 10.

### 4.1.4. Modelo GBM (Stochastic Gradient Boosting)

El modelo GBM o Potenciacion del gradiente, es una técnica de machine learning utilizada para problemas de analisis de regresion y clasificación estadistica. Esta técnica produce un modelo predictivo en forma de conjunto de modelos de predicción débiles, normalmente árboles de decisión. El modelo se construye de forma escalonada como lo hacen otros métodos de boosting, es decir, los predictores no se forman de manerera independiente, si no, de manera secuencial.


![Imagen de Baggin y Boosting](boosting.png)
Bagging (independent models) & Boosting (sequential models). Reference: https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/

La principal diferencia entre Baggin y Boosting es que en Bagging se construye los predictores de manera independiente y luego se combinan y en el Boosting se construyen de manera dependediente y secuencialmente.



Calcularemos las semillas para usarlas en la función trainControl que pasaremos al entrenamientod de los modelos


## 4.2. Encontrar los mejores hiper-parámetros (usar TunerGrid en, al menos, 1 modelo)


### 4.2.1. Modelo GLM

El modelo glm no tiene hiper-parametros por lo que no se puede modficar nada.

```{r}
modelLookup("glm")
```

### 4.2.2. Modelo RPART

El modelo rpart tiene como único parámetro el cp.

```{r}
modelLookup("rpart")
```

### 4.2.3. Modelo RF

El modelo rf tiene como único parámetro el mtry.

```{r}
modelLookup("rf")
```


### 4.2.4. Modelo GBM (Stochastic Gradient Boosting)

Encontramos los hiperparametros para este modelo:

```{r}
modelLookup("gbm")
```


Vemos que existen 4 hiper-parametros: n.trees, interaction.depth, shrinkage y n.minobsinnode.
Estos serán los que modificaremos utilizando TuneGrid. Basicamente, TuneGrid hace posible que se pueda pasar una parrilla de combianciones a la función train().

```{r}
credit.Train.gbm.grid <- expand.grid(
  n.trees=c(100,200,500,1000,2000),
  shrinkage=c(0.01,0.05,0.1),
  n.minobsinnode = c(3,5,10,15),
  interaction.depth=c(1,2,5,10)
)
```



## 4.3. Probar, al menos, un mismo modelo/técnica con 2 preprocesos de datos diferentes

### 4.3.1 Modelos con datos sin transformar

En este entrenamiento usaremos el conjunto de datos de credit.Datos.Train, que solo tiene tratando los outliners y nulos.

```{r}
set.seed(1234) ## Para la repetición de la ejecución de los modelos
# seedsLength es = (numero_repeticiones*numero_remuestreos)+1, seguiremos lo visto en clase y usaremos los valores: (3*10)+1
seedsLength=31
seeds <- vector(mode = "list", length = seedsLength)

# Crearemos unos pliegues para usar los mismos en todos los modelos diferentes
foldIndexes<-createMultiFolds(credit.Datos.Train[[credit.Var.Salida.Usada]],k=10,times=3)

# combHParam es el n´umero de combinaciones de hiper-par´ametros a probar
combHParam=100
for(i in 1:seedsLength) seeds[[i]]<- sample.int(n=1000, combHParam)
#H ay que crear una semilla ´unica para el modelo final a entrenar.
seeds[[seedsLength+1]]<-sample.int(1000, 1)

# TrainControl con seeds
credit.Train.Control.CV1 <- trainControl(method = "repeatedcv",number=10, repeats=3, verboseIter=F, returnResamp = "all", seeds=seeds ) # Guardamos todo para hacer diagramas


# Ejecutar el modelo en paralelo (se deja un core siempre libre o se "congela" la consola)
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)

#Ejecutar Modelos
#Modelo gbm con tuneGrid
set.seed(1234)
credit.Train.gbm.nt<-train(credit.Datos.Train[credit.Vars.Entrada.Usadas], credit.Datos.Train[[credit.Var.Salida.Usada]], method='gbm', trControl=credit.Train.Control.CV1, tuneGrid=credit.Train.gbm.grid, verbose=FALSE)

#Modelo glm
set.seed(1234)
credit.Train.glm.nt<-train(credit.Datos.Train[credit.Vars.Entrada.Usadas], credit.Datos.Train[[credit.Var.Salida.Usada]], method='glm', trControl = credit.Train.Control.CV1)

#Modelo RF con tuneLength
set.seed(1234)
credit.Train.rf.nt<-train(credit.Datos.Train[credit.Vars.Entrada.Usadas], credit.Datos.Train[[credit.Var.Salida.Usada]], method='rf', trControl=credit.Train.Control.CV1, tuneLength = 4)

#Modelo RF con tuneLength
set.seed(1234)
credit.Train.rpart.nt<-train(credit.Datos.Train[credit.Vars.Entrada.Usadas], credit.Datos.Train[[credit.Var.Salida.Usada]], method='rpart', trControl=credit.Train.Control.CV1, tuneLength = 10)


# Volvemos al modo no paralelo
stopImplicitCluster()
stopCluster(cl)
registerDoSEQ()
```


Y aquí los mejores resultados de cada modelo:
```{r}
credit.Train.gbm.nt$bestTune
max(credit.Train.gbm.nt$results$Accuracy)


#glm no tiene hiper-parametros
max(credit.Train.glm.nt$results$Accuracy)


credit.Train.rf.nt$bestTune
max(credit.Train.rf2.nt$results$Accuracy)

credit.Train.rpart.nt$bestTune
max(credit.Train.rpart.nt$results$Accuracy)

```

Se puede observar que GBM ha conseguido el mejor resultado




### 4.3.2 Modelos con datos transformados

En este entrenamiento usaremos el conjunto de datos de credit.Train.Preprocesado, donde eliminamos y creamos variables y transformamos las que tenía.

```{r}
set.seed(1234)
seedsLength=31
seeds <- vector(mode = "list", length = seedsLength)

# Crearemos unos pliegues para usar los mismos en todos los modelos diferentes
foldIndexes<-createMultiFolds(credit.Train.Preprocesado[[credit.Var.Salida.Usada]],k=10,times=3)

# combHParam es el n´umero de combinaciones de hiper-par´ametros a probar
combHParam=100
for(i in 1:seedsLength) seeds[[i]]<- sample.int(n=1000, combHParam)
#H ay que crear una semilla ´unica para el modelo final a entrenar.
seeds[[seedsLength+1]]<-sample.int(1000, 1)

# TrainControl con seeds
credit.Train.Control.CV2 <- trainControl(method = "repeatedcv",number=10, repeats=3, verboseIter=F, returnResamp = "all", seeds=seeds ) # Guardamos todo para hacer diagramas


# Ejecutar el modelo en paralelo (se deja un core siempre libre o se "congela" la consola)
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)

#Ejecutar Modelos
#Modelo gbm con tuneGrid
set.seed(1234)
credit.Train.gbm.t<-train(credit.Train.Preprocesado[credit.Vars.Entrada.Usadas], credit.Train.Preprocesado[[credit.Var.Salida.Usada]], method='gbm', trControl=credit.Train.Control.CV2, tuneGrid=credit.Train.gbm.grid, verbose=FALSE)

#Modelo glm
set.seed(1234)
credit.Train.glm.t<-train(credit.Train.Preprocesado[credit.Vars.Entrada.Usadas], credit.Train.Preprocesado[[credit.Var.Salida.Usada]], method='glm', trControl = credit.Train.Control.CV2)

#Modelo RF con tuneLength
set.seed(1234)
credit.Train.rf.t<-train(credit.Train.Preprocesado[credit.Vars.Entrada.Usadas], credit.Train.Preprocesado[[credit.Var.Salida.Usada]], method='rf', trControl=credit.Train.Control.CV2, tuneLength = 4)

#Modelo RPART con tuneLength
set.seed(1234)
credit.Train.rpart.t<-train(credit.Train.Preprocesado[credit.Vars.Entrada.Usadas], credit.Train.Preprocesado[[credit.Var.Salida.Usada]], method='rpart', trControl=credit.Train.Control.CV2, tuneLength = 10)


# Volvemos al modo no paralelo
stopImplicitCluster()
stopCluster(cl)
registerDoSEQ()

```

Y aquí los mejores resultados de cada modelo:
```{r}
credit.Train.gbm.t$bestTune
max(credit.Train.gbm.t$results$Accuracy)


#glm no tiene hiper-parametros
max(credit.Train.glm.t$results$Accuracy)


credit.Train.rf.t$bestTune
max(credit.Train.rf.t$results$Accuracy)

credit.Train.rpart.t$bestTune
max(credit.Train.rpart.t$results$Accuracy)

```

Se puede observar que GBM ha conseguido el mejor resultado



# 5. Comparar Modelos

## 5.1. Comparar el rendimiento de los diferentes modelos

### Modelo GBM (Stochastic Gradient Boosting)
La mejor combiancion de hiper-parametros y el mejor resultado es la siguiente.

Para los datos transformados:
```{r}
credit.Train.gbm.t$bestTune
max(credit.Train.gbm.t$results$Accuracy)
```

Y sin transformar:

```{r}
credit.Train.gbm.nt$bestTune
max(credit.Train.gbm.nt$results$Accuracy)
```


Se puede observar que la configuracion de hiper-parametros es la misma para los dos. Sin embargo, este modelo ha funcionado ligeramente mejor con los datos sin transformar.




Grafico de la precision del modelo frente a los hiper-parametros (Datos Transformados)
```{r}
# Incrementamos el número de lineas que muestra print
options(max.print = 10000)
# Usamos escala logaritmica en el eje x
plot(credit.Train.gbm.t,scales=list(x=list(log=T)))
options(max.print = 1000)
```


Grafico de la precision del modelo frente a los hiper-parametros (Datos Sin Transformar)
```{r}
# Incrementamos el número de lineas que muestra print
options(max.print = 10000)
# Usamos escala logaritmica en el eje x
plot(credit.Train.gbm.nt,scales=list(x=list(log=T)))
options(max.print = 1000)
```




Grafico del valor estadistico Kappa frente a los hiper-parametros (Datos Transformados)
```{r}
plot(credit.Train.gbm.t, metric = "Kappa")
```


Grafico del valor estadistico Kappa frente a los hiper-parametros (Datos Sin Transformar)
```{r}
plot(credit.Train.gbm.nt, metric = "Kappa")
```



Grafico de nivel, precision frente a hiper-parametros (Datos Transformados)

```{r}
plot(credit.Train.gbm.t, plotType = "level")
```

Grafico de nivel, precision frente a hiper-parametros (Datos Sin Transformar)

```{r}
plot(credit.Train.gbm.nt, plotType = "level")
```


Grafico de densidad para Accuracy y Kappa del modelo final (Datos Transformados)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.gbm.t)
```

Grafico de densidad para Accuracy y Kappa del modelo final (Datos Sin Transformar)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.gbm.nt)
```



Hay ligeras diferencias entre ambos conjuntos de datos pero el resultado es prácticamente el mismo.



### Modelo GLM
Ya que GLM no tiene hiper-parametros, no existe una mejor configuracion.Aun así, el mejor resultado es la siguiente.

Para los datos transformados:
```{r}
max(credit.Train.glm.t$results$Accuracy)
```

Y sin transformar:

```{r}
max(credit.Train.glm.nt$results$Accuracy)
```


Observamos que para los datos sin transformar se obtine un resultado ligeramente superior.


Como hemos dicho antes, al no existir hiper-parametros no se puede dibujar ninguna grafica que contemple cambios enrte los resultados y los parametros. Pero si es posible dibujar el grafico de la distribuciond e remuestreo:


Grafico de densidad para Accuracy y Kappa del modelo final (Datos Transformados)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.glm.t)
```

Grafico de densidad para Accuracy y Kappa del modelo final (Datos Sin Transformar)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.glm.nt)
```
Ambos son muy similares.


### Modelo RPART
La mejor combiancion de hiper-parametros y el mejor resultado es la siguiente.

Para los datos transformados:
```{r}
credit.Train.rpart.t$bestTune
max(credit.Train.gbm.t$results$Accuracy)
```

Y sin transformar:

```{r}
credit.Train.rpart.nt$bestTune
max(credit.Train.gbm.nt$results$Accuracy)
```


Se puede observar que la configuracion de hiper-parametros es la misma para los dos. Sin embargo, este modelo ha funcionado ligeramente mejor con los datos sin transformar.


Grafico de la precision del modelo frente a los hiper-parametros (Datos Transformados)
```{r}
# Incrementamos el número de lineas que muestra print
options(max.print = 10000)
# Usamos escala logaritmica en el eje x
plot(credit.Train.rpart.t,scales=list(x=list(log=T)))
options(max.print = 1000)
```


Grafico de la precision del modelo frente a los hiper-parametros (Datos Sin Transformar)
```{r}
# Incrementamos el número de lineas que muestra print
options(max.print = 10000)
# Usamos escala logaritmica en el eje x
plot(credit.Train.rpart.nt,scales=list(x=list(log=T)))
options(max.print = 1000)
```




Grafico del valor estadistico Kappa frente a los hiper-parametros (Datos Transformados)
```{r}
plot(credit.Train.rpart.t, metric = "Kappa")
```


Grafico del valor estadistico Kappa frente a los hiper-parametros (Datos Sin Transformar)
```{r}
plot(credit.Train.rpart.nt, metric = "Kappa")
```




Grafico de densidad para Accuracy y Kappa del modelo final (Datos Transformados)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.rpart.t)
```

Grafico de densidad para Accuracy y Kappa del modelo final (Datos Sin Transformar)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.rpart.nt)
```



Hay ligeras diferencias entre ambos conjuntos de datos pero el resultado es prácticamente el mismo.


### Modelo RF

La mejor combiancion de hiper-parametros y el mejor resultado es la siguiente.

Para los datos transformados:
```{r}
credit.Train.rf.t$bestTune
max(credit.Train.rf.t$results$Accuracy)
```

Y sin transformar:

```{r}
credit.Train.rf.nt$bestTune
max(credit.Train.rf.nt$results$Accuracy)
```

En este caso se ha obtenido un mejor resultado con los datos transformados.



Grafico de la precision del modelo frente a los hiper-parametros (Datos Transformados)
```{r}
# Incrementamos el número de lineas que muestra print
options(max.print = 10000)
# Usamos escala logaritmica en el eje x
plot(credit.Train.rf.t,scales=list(x=list(log=T)))
options(max.print = 1000)
```


Grafico de la precision del modelo frente a los hiper-parametros (Datos Sin Transformar)
```{r}
# Incrementamos el número de lineas que muestra print
options(max.print = 10000)
# Usamos escala logaritmica en el eje x
plot(credit.Train.rf.nt,scales=list(x=list(log=T)))
options(max.print = 1000)
```




Grafico del valor estadistico Kappa frente a los hiper-parametros (Datos Transformados)
```{r}
plot(credit.Train.rf.t, metric = "Kappa")
```


Grafico del valor estadistico Kappa frente a los hiper-parametros (Datos Sin Transformar)
```{r}
plot(credit.Train.rf.nt, metric = "Kappa")
```



Grafico de densidad para Accuracy y Kappa del modelo final (Datos Transformados)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.rf.t)
```

Grafico de densidad para Accuracy y Kappa del modelo final (Datos Sin Transformar)
Dibuja el grafico de la distribucion de remuestreo
```{r}
resampleHist(credit.Train.rf.nt)
```


Ambos resultados son muy parecidos.



## 5.2. Decidir justificadamente el modelo final

## 5.3. Evaluar el rendimiento futuro del modelo final







